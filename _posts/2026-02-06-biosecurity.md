---
title: "Open Letter to Valthos: Why I Want to Spend the Next Five Years on Biosecurity"
date: 2026-02-06
permalink: /posts/2026/2/biosecurity/
tags:
  - 
---

Biology has become programmable. The same AI capabilities driving drug discovery and protein design can be turned toward engineering pathogens. It's the explicit concern behind CAIS reports, behind OpenAI's investment in defensive biosecurity, behind the RAND Corporation's warnings that governments remain unprepared for AI-accelerated biological crises. But the threat that occupies more of my thinking since my work trial with Valthos isn't the bad actor with a laptop. It's the quiet, relentless work that evolution does on its own. Novel pathogens don't need to be engineered. They emerge constantly in recombination events in animal reservoirs, antigenic drift in circulating strains, spillover from species we barely monitor. COVID-19 wasn't engineered. H5N1 circulating in dairy cattle right now wasn't engineered. The next pandemic probably won't be either. And yet our ability to take a newly sequenced pathogen and rapidly answer "what do we already have that works against this?" remains primitive. The engineered threat makes the problem more acute and more urgent, but the natural one is and has always been here, already killing people, and severely outpacing our reactive response infrastructure.

The asymmetry is what gets me. It is faster today to weaponize biology than to develop new cures. A novel pathogen can be engineered and released in week. Developing a new therapeutic takes years. One severely underexplored but viable defense is to make the response faster. Detect threats early, characterize them rapidly, and update medical countermeasures in real time rather than starting from scratch each time.

But, after some time ruminating since the work trial, I want to be specific about what I think the hardest and most important problems actually are and which ones I resonate with the most, because "biosecurity" is broad.

The bottleneck I keep coming back to is the gap between characterization and response. Detection is getting better. Wastewater surveillance, metagenomic sequencing, environmental monitoring are all improving. We're increasingly able to notice that something new is circulating. But noticing isn't enough. The moment you identify a novel sequence, the clock starts, and the questions that follow are the ones we're worst at answering quickly: Is this thing susceptible to anything we already have? If not, how far off are our closest existing countermeasures? What's the fastest path to something that works?

This is where I think the field underestimates the difficulty. Most current approaches treat countermeasure matching as a homology problem — if the new target looks similar to a known target, assume similar drugs work. That's reasonable for closely related variants but, as I doved into this rabbit hole deeper during my work trial, I saw that this breaks down exactly when it matters most like when a pathogen has mutated in or near the drug binding pocket, or when the threat is engineered to evade known therapeutics. These are the scenarios where structural and functional reasoning about drug-target interactions becomes essential, and where sequence similarity alone gives false confidence.

I also think there's a priority mismatch in how the bioML community allocates attention. An enormous amount of effort goes into de novo protein design and binder generation but comparatively little goes into the arguably more urgent question of triaging existing stockpiles against emerging threats. Designing a new therapeutic from scratch takes years to validate clinically. Knowing that an existing, approved drug in a government stockpile still works against a new variant is actionable immediately. The expected value of fast, reliable countermeasure matching is enormous relative to the attention it gets.

And this is fundamentally a computational problem. Not exclusively of course. You need wet labs, clinical trials, manufacturing, distribution. But the bottleneck that determines whether we respond in hours versus months is computational. Can we identify a new biological sequence and immediately assess which existing drugs might still work? Can we predict which mutations will evade our stockpiled countermeasures before those mutations emerge in the wild? Can we design updated therapeutics computationally and hand pharmaceutical partners a viable candidate on day one?

I've spent years studying how AI models encode, or fail to encode, the structural and functional relationships that determine biological activity. At MIT, I found that state-of-the-art protein models were sometimes blind to the very sites that determine whether a molecule becomes medicine. At Altera and Ritual, AI agents can feign compentence and appear capable while missing fundamental reasoning structures. The pattern was always the same: models that optimize for the wrong and nonpractical objectives learn correlations instead of mechanisms. They perform well on benchmarks that get them published but fail exactly when the stakes are real, when the distribution shifts, when a novel variant appears.

Biosecurity is where this failure mode has the highest cost. And these questions sit at the exact intersection of my skills and my convictions.

I spent time with nearly everyone at the company before and during the work trial, and each conversation reshaped how I understood the problem. Chatting with Ria, I learned about temporal data splits, how open-source protein language models leave out long-tail functional diversity in their training data, which means you can't just use them out of the box for the kinds of sequences Valthos cares about most. She talked about designing metrics from first principles, reconstructing phylogenetic trees and clades, thinking carefully about what clusters together rather than over-engineering metrics without precedent. That conversation made me realize how much depth exists in getting the foundations right, and how my background in protein representations plugs directly into that effort.

Talking with Tina, I saw someone who'd built exactly the kind of role they wanted, wearing many hats across coding, model training, and product design. She was candid about what makes building in this space different: you can't just follow the YC handbook, you can't just talk to customers, you have to be opinionated about the problem space and offer something they need before they know to ask for it. That stuck with me. And something about the meetigns I sat in on, maybe it was the directness, maybe it was hearing people talk about threats to human health as more than just engineering problems with deadlines, brought me back to earlier experiences I hadn't fully connected to this work. I spent years as an EMT, riding overnight ambulance shifts, sitting with people in the worst moments of their lives. There's nothing abstract about human fragility when you're holding someone's hand at 3 AM. That part of me, the part that chose premed, that wanted to be patient-facing, that cared about whether help actually reaches people, has been dormant through most of my academic career. Talking with Tina and the rest of the team made me realize it doesn't have to be. Biosecurity lets me work on the same question I cared about as an EMT - how do we make sure people get the help they need, fast, but at a scale where the answer is computational, which is where I'm most useful.

Similarly with Kathleen, she said something that reframed how I think about impact. Valthos isn't trying to push the frontier for its own sake. It's trying to solve the distribution problem and earn the right to be in the room where impactful questions get asked and decisions get made. That distinction matters to me. I've spent my academic career thus far optimizing numbers and metrics. What I want now is to be somewhere that optimizes for whether the answer reaches the people who need it.

On the technical side, every result I produced was immediately contextualized against a real threat. When I discovered that fitness filtering eliminates most resistant variants from consideration, the response expected from me was more than "interesting finding, let's write it up." It was "good! that means the problem is more tractable than it looks, and here's how we use that." When the structural metrics failed, the question was what to try next, because the operational need doesn't care about paper cycles. Failure, reframing, progress, all against the backdrop of something that actually matters is what convinced me this is the right problem. Not the science itself, which I'd encounter in any good computational biology lab. The urgency behind it.

There are many ways to contribute to biosecurity. The reason I want to do it at Valthos specifically comes down to three things I observed:

Valthos isn't trying to build a general-purpose biotech platform and hoping it helps with security. The company is organized around a specific, urgent mission: identify biological threats and update medical countermeasures in real time. The budding MCM matching pipeline I worked in where you take a novel sequence, find structurally similar known targets, and assess whether existing drugs will still bind is a system that needs to exist and doesn't yet work well enough. Every piece of infrastructure is oriented toward answering a concrete operational question: will this drug still work against this variant?

Even in a short stint, I could see how the team operates. Each person carries a spike that meshes and overlaps with, but never duplicates, the others. No one is replaceable by anyone else. And spending three days embedded in that, I started to see the piece I could carve out for myself: the bridge between protein representation learning and operational countermeasure prediction. The work I've done on how models encode (and miss) functional substructures isn't something anyone else on the team is focused on, but it plugs directly into the hardest open problems in the MCM pipeline.

Valthos is early enough that individual contributions shape the technical direction, but mature enough to have real infrastructure and real partnerships with government and pharma. When I built the differential binding scoring approach during my trial, it wasn't a research exercise, it was a module intended to integrate into a production system. That proximity between research and impact is what I want.

I don't want to just write code. I want to grow into someone who thinks carefully about biosecurity as a field — where the highest-priority threats are, what the highest-EV technical approaches look like, how to communicate those ideas to policymakers and investors. I want to write technical blogs about model capabilities. I want to sit in the meetings where we decide where to spend our effort next. The work trial project is exactly the kind of work I love, iterating on hypotheses quickly to answer hard questions, but I also want to be part of shaping which questions we ask in the first place.

With this, I want to reiterate what I would work on next. The differential binding approach I prototyped during the trial is a starting point, not a solution. The first thing I want to do is make resistance prediction actually work by pushing it in two directions. Improve the signal with better structure predictors, ensemble methods, and learned pocket representations that capture the physics of drug-target binding rather than relying on geometric heuristics. And generalize beyond neuraminidase by developing methods that transfer across protein families, drug classes, and pathogen types, because in a real threat scenario, you won't have thousands of DMS measurements to calibrate against. This is where my work on protein representations directly applies. The insight that models need to explicitly encode functional substructures translates directly to building pocket-aware representations for countermeasure prediction.

From there, I want to close the loop between detection and response. Identifying that a variant is resistant to a stockpiled drug is only half the problem. The other half is predicting what modifications to the drug (or what alternative compounds) would restore efficacy. That means moving from classification (will this drug work?) to generation (what drug will work?). Generative models for countermeasure adaptation that take a characterized threat as input and propose molecular modifications ranked by predicted binding affinity, synthetic accessibility, and pharmacological plausibility.

And ultimately, the vision is a system that makes the next pandemic different. A pipeline and deployed system that government agencies actually are commited to using where a novel biological sequence enters one end and actionable countermeasure intelligence comes out the other (eg which existing drugs still work, which don't, what modifications would restore them, and what entirely new candidates are worth pursuing).

This is ambitious. I know that. But during my three days at Valthos, I watched myself arrive at insights that changed how I think about the problem, and write code that integrated directly into a production system. If I can do that in three days, I want to find out what five years looks like.